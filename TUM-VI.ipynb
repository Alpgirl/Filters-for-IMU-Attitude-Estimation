{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9072b21-4c8a-4dc3-8110-2edfafe869bf",
   "metadata": {},
   "source": [
    "# AHRS\n",
    "\n",
    "This Notebook showcases the most important classes and functions included in the Python package `ahrs`.\n",
    "\n",
    "Here we will explore the basic use of:\n",
    "\n",
    "- Class [DCM](https://ahrs.readthedocs.io/en/latest/dcm/classDCM.html)\n",
    "- Class [Quaternion](https://ahrs.readthedocs.io/en/latest/quaternion/classQuaternion.html)\n",
    "- Class [QuaternionArray](https://ahrs.readthedocs.io/en/lamy/quaternion/classQuaternionArray.html)\n",
    "- The new class [Sensors](https://ahrs.readthedocs.io/en/latest/sensors.html) to simulate sensor data.\n",
    "- The use of [Attitude estimation algorithms](https://ahrs.readthedocs.io/en/latest/filters.html).\n",
    "- [Metrics functions](https://ahrs.readthedocs.io/en/latest/metrics.html) for orientation representations.\n",
    "- The [World Magnetic Model](https://ahrs.readthedocs.io/en/latest/wmm.html)\n",
    "- The [World Geodetic System](https://ahrs.readthedocs.io/en/latest/wgs84.html)\n",
    "- And diverse tools included in `ahrs`.\n",
    "\n",
    "### Helping Packages\n",
    "\n",
    "Plotting and data-handling tools are imported from the script `tools.py` located in the current directory.\n",
    "\n",
    "- `plot` shows time-series data in vertically stacked plots.\n",
    "- `plot3` shows a 3D scene, where particles, frames, and items exist and interact in the same space.\n",
    "\n",
    "Packages `matplotlib` and `ipympl` are required to build interactive visualizations in the Notebook. Make sure you have those installed.\n",
    "\n",
    "These tools simplify the visualization of orientations in 3d, or time-series data, but are **NOT** included in the `ahrs` package.\n",
    "\n",
    "Once you have `ahrs` installed (which also installs `numpy`) and you have the forementioned libraries, we can start by setting our notebook up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from madgwick_filter import compare, data_processing, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b78e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use widgets\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "# Import plotting tools\n",
    "from madgwick_filter.tools_ahrs import plot\n",
    "from madgwick_filter.tools_ahrs import plot3\n",
    "import ahrs\n",
    "import mrob\n",
    "import twistnsync as tns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.rcParams['font.size'] = 14\n",
    "# Seed random generator\n",
    "GENERATOR = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d05048-ac7c-4c21-b659-461d2bae098a",
   "metadata": {},
   "source": [
    "## Attitude Estimators\n",
    "\n",
    "Perhaps the most valued contribution of `ahrs` is its collection of attitude estimation algorithms. You can find a list [here](https://ahrs.readthedocs.io/en/lamy/filters.html)\n",
    "\n",
    "Let's jut explore one famous example: The [Madgwick Filter](https://ahrs.readthedocs.io/en/lamy/filters/madgwick.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_path = os.path.join(\"madgwick_filter\", \"TUM-VI\", \"imu0\")\n",
    "mocap_path = os.path.join(\"madgwick_filter\", \"TUM-VI\", \"mocap0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "take_name = \"room4.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72fd26c",
   "metadata": {},
   "source": [
    "# Madgwick filter and game rotation vector comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_base, data_gyr, data_acc = data_processing.import_tum_imu(os.path.join(x3_path, take_name), smoothing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale = 1\n",
    "t_base, data_gyr, data_acc = data_processing.downsample(downscale, t_base, data_gyr, data_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_gyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_my = 120/downscale # Hz\n",
    "# if frequency of MoCap is lower than resulting from data - change to MoCap's 240 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32e09f",
   "metadata": {},
   "source": [
    "Now that we generated IMU data, we can use it to estimate the original attitudes (orientations) with our Madgwick Filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c16df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "madgwick_IMU = ahrs.filters.Madgwick(gyr=data_gyr,\n",
    "                                 acc=data_acc,\n",
    "                                 frequency=freq_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449bb1c",
   "metadata": {},
   "source": [
    "Done!\n",
    "\n",
    "The `Madgwick` object uses the given arrays to immediately perform the full computation of the orientations.\n",
    "\n",
    "These orientations are in an $N\\times 4$ array accessible in the attribute called `Q` (stands for Quaternions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ec56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(madgwick_IMU.Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb660c6",
   "metadata": {},
   "source": [
    "Q = [w i j k] - [red green blue gold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a62cb7",
   "metadata": {},
   "source": [
    "# Here goes comparison with Motion Capture as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mocap_t, data_mocap_q, data_mocap_T = data_processing.import_tum_mocap(os.path.join(mocap_path, take_name), smoothing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mocap_t, data_mocap_q, data_mocap_T = data_processing.downsample(downscale, data_mocap_t, data_mocap_q, data_mocap_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_mocap_q, madgwick_IMU.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc175e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mocap_t - data_mocap_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_mocap_t - data_mocap_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_base - t_base[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a098d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_data_zeroed = (t_base - t_base[0]) / 1000\n",
    "t_base, data_gyr, data_acc, data_acc, data_mocap_q = data_processing.sync_mocap_and_data(data_mocap_t, data_mocap_q, t_base, data_gyr, data_acc, data_acc)\n",
    "# no more need in sync, because it's done after TwistnSync launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_start = 0\n",
    "t_base, data_gyr, data_acc, data_mocap_t, data_mocap_q = data_processing.arrays_from_i(i_start, t_base, data_gyr, data_acc, data_mocap_t, data_mocap_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "madgwick_shifted_IMU = ahrs.filters.Madgwick(gyr=data_gyr,\n",
    "                                 acc=data_acc,\n",
    "                                 frequency=freq_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(madgwick_shifted_IMU.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_mocap_q, madgwick_shifted_IMU.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "quat_sm_aligned = madgwick_shifted_IMU.Q\n",
    "quat_mocap_aligned = data_mocap_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.errors_estimation(quat_sm_aligned, quat_mocap_aligned, source1=\"sensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3726f9",
   "metadata": {},
   "source": [
    "# Sensors and Mocap data sync\n",
    "\n",
    "More information can be found in the [paper](https://www.mdpi.com/1424-8220/21/1/68).\n",
    "\n",
    "Here we find time offset and relative transformation between TUM-VI sensors output and Motion Capture system data of tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8038c",
   "metadata": {},
   "source": [
    "## Filter without magnetometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sync_imu, qsa, qra = compare.compare_smartphone_to_mocap(t_base, madgwick_shifted_IMU.Q, data_gyr,\n",
    "                                                          data_mocap_t, data_mocap_q, 100, source1=\"sensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439a1f1",
   "metadata": {},
   "source": [
    "# Different plots\n",
    "\n",
    "So this growing error (both APEs of R and g) in compare_to_mocap is just an integration (angvels -> quats) error. Maybe in my data it's also integration error?\n",
    "\n",
    "How to mitigate? We can't rotate acc vector, tried\n",
    "\n",
    "Maybe we can force sync quats when RPE is 0 ( -> now undistorted estimation)??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
