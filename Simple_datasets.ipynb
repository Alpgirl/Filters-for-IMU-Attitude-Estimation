{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9072b21-4c8a-4dc3-8110-2edfafe869bf",
   "metadata": {},
   "source": [
    "# AHRS\n",
    "\n",
    "This Notebook showcases the most important classes and functions included in the Python package `ahrs`.\n",
    "\n",
    "Here we will explore the basic use of:\n",
    "\n",
    "- Class [DCM](https://ahrs.readthedocs.io/en/latest/dcm/classDCM.html)\n",
    "- Class [Quaternion](https://ahrs.readthedocs.io/en/latest/quaternion/classQuaternion.html)\n",
    "- Class [QuaternionArray](https://ahrs.readthedocs.io/en/lamy/quaternion/classQuaternionArray.html)\n",
    "- The new class [Sensors](https://ahrs.readthedocs.io/en/latest/sensors.html) to simulate sensor data.\n",
    "- The use of [Attitude estimation algorithms](https://ahrs.readthedocs.io/en/latest/filters.html).\n",
    "- [Metrics functions](https://ahrs.readthedocs.io/en/latest/metrics.html) for orientation representations.\n",
    "- The [World Magnetic Model](https://ahrs.readthedocs.io/en/latest/wmm.html)\n",
    "- The [World Geodetic System](https://ahrs.readthedocs.io/en/latest/wgs84.html)\n",
    "- And diverse tools included in `ahrs`.\n",
    "\n",
    "### Helping Packages\n",
    "\n",
    "Plotting and data-handling tools are imported from the script `tools.py` located in the current directory.\n",
    "\n",
    "- `plot` shows time-series data in vertically stacked plots.\n",
    "- `plot3` shows a 3D scene, where particles, frames, and items exist and interact in the same space.\n",
    "\n",
    "Packages `matplotlib` and `ipympl` are required to build interactive visualizations in the Notebook. Make sure you have those installed.\n",
    "\n",
    "These tools simplify the visualization of orientations in 3d, or time-series data, but are **NOT** included in the `ahrs` package.\n",
    "\n",
    "Once you have `ahrs` installed (which also installs `numpy`) and you have the forementioned libraries, we can start by setting our notebook up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from madgwick_filter import compare, data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b78e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use widgets\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "# Import plotting tools\n",
    "from madgwick_filter.tools_ahrs import plot\n",
    "from madgwick_filter.tools_ahrs import plot3\n",
    "import ahrs\n",
    "import mrob\n",
    "import twistnsync as tns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.rcParams['font.size'] = 14\n",
    "# Seed random generator\n",
    "GENERATOR = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d05048-ac7c-4c21-b659-461d2bae098a",
   "metadata": {},
   "source": [
    "## Attitude Estimators\n",
    "\n",
    "Perhaps the most valued contribution of `ahrs` is its collection of attitude estimation algorithms. You can find a list [here](https://ahrs.readthedocs.io/en/lamy/filters.html)\n",
    "\n",
    "Let's jut explore one famous example: The [Madgwick Filter](https://ahrs.readthedocs.io/en/lamy/filters/madgwick.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_path = \"madgwick_filter/recordings/X3_simple/Walking_2025-03-06_18-37-32.144_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/standing_still_2025-03-05_19-11-59.134_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/basic_motions_2025-03-05_19-05-58.195_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/walking_2025-03-05_18-54-04.492_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/walking_talking_2025-03-05_19-01-51.858_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/Standing_still_2025-03-06_18-50-19.416_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/Basic_motions_2025-03-06_18-45-09.848_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/Walking_2025-03-06_18-37-32.144_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/Walking_talking_2025-03-06_18-41-53.764_TGW\"\n",
    "# x3_path = \"madgwick_filter/recordings/X3_simple/Random_walk_2025-03-06_19-02-36.207_TGW\"\n",
    "mocap_path = \"madgwick_filter/recordings/Mocap_simple/Walking_Take 2025-03-06 06.38.58 PM.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/standing_still_Take 2025-03-05 06.55.27 PM.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/basic_motions_Take 2025-03-05 06.55.27 PM.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/walking_Take 2025-03-05 06.55.27 PM.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/walking_talking_Take 2025-03-05 06.55.27 PM.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/Standing_still_Take 2025-03-06 06.38.58 PM_003.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/Basic_motions_Take 2025-03-06 06.38.58 PM_002.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/Walking_Take 2025-03-06 06.38.58 PM.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/Walking_talking_Take 2025-03-06 06.38.58 PM_001.csv\"\n",
    "# mocap_path = \"madgwick_filter/recordings/Mocap_simple/Random_walk_Take 2025-03-06 06.38.58 PM_004.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72fd26c",
   "metadata": {},
   "source": [
    "# Madgwick filter and game rotation vector comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sm, data_gyr, data_acc, data_magn = data_processing.import_combined_data(os.path.join(x3_path, \"combined_imu_data_7.csv\"))\n",
    "t_sm = t_sm / 1000                  # ms to s\n",
    "\n",
    "t_grv, gamerotvec = data_processing.import_gamerotvec_data(os.path.join(x3_path, \"game_rotation_vector_12.csv\"))\n",
    "t_grv = t_grv / 1000                  # ms to s\n",
    "\n",
    "compare.compare_smartphone_to_gamerotvec(t_sm, data_gyr, data_acc, data_magn, t_grv, gamerotvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b020c3d",
   "metadata": {},
   "source": [
    "# Madgwick filter and game rotation vector comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mocap_t, data_mocap_q, data_mocap_T, data_mocap_Markers_xyz = data_processing.import_mocap_data(mocap_path)\n",
    "\n",
    "compare.compare_gamerotvec_to_mocap(t_grv, gamerotvec, data_mocap_t, data_mocap_q, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_gyr_t_my, data_gyr_my = data_processing.import_data(os.path.join(x3_path, \"gyroscope_3.csv\"))\n",
    "#data_acc_t_my, data_acc_my = data_processing.import_data(os.path.join(x3_path, \"accelerometer_1.csv\"))\n",
    "#data_magn_t_my, data_magn_my = data_processing.import_data(os.path.join(x3_path, \"magnetic_field_5.csv\"))\n",
    "\n",
    "#downscale = 1\n",
    "#t_base = data_magn_t_my[::downscale]\n",
    "#t_base, data_gyr_my_sync, data_acc_my_sync, data_magn_my_sync = data_processing.sync_data(t_base, data_gyr_t_my, data_gyr_my, data_acc_t_my, data_acc_my, data_magn_t_my, data_magn_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_base, data_gyr, data_acc, data_magn = data_processing.import_combined_data(os.path.join(x3_path, \"combined_imu_data_7.csv\"))\n",
    "t_base = t_base/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale = 1\n",
    "t_base, data_gyr, data_acc, data_magn = data_processing.downsample(downscale, t_base, data_gyr, data_acc, data_magn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_gyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_gyr.shape)\n",
    "print(data_acc.shape)\n",
    "print(data_magn.shape)\n",
    "freq_my = 100/downscale # Hz\n",
    "# if frequency of MoCap is lower than resulting from data - change to MoCap's 240 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32e09f",
   "metadata": {},
   "source": [
    "Now that we generated IMU data, we can use it to estimate the original attitudes (orientations) with our Madgwick Filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c16df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "madgwick_MARG = ahrs.filters.Madgwick(gyr=data_gyr,\n",
    "                                 acc=data_acc,\n",
    "                                 mag=data_magn,\n",
    "                                 frequency=freq_my)\n",
    "\n",
    "madgwick_IMU = ahrs.filters.Madgwick(gyr=data_gyr,\n",
    "                                 acc=data_acc,\n",
    "                                 frequency=freq_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449bb1c",
   "metadata": {},
   "source": [
    "Done!\n",
    "\n",
    "The `Madgwick` object uses the given arrays to immediately perform the full computation of the orientations.\n",
    "\n",
    "These orientations are in an $N\\times 4$ array accessible in the attribute called `Q` (stands for Quaternions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ec56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(madgwick_IMU.Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb660c6",
   "metadata": {},
   "source": [
    "Q = [w i j k] - [red green blue gold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a62cb7",
   "metadata": {},
   "source": [
    "# Here goes comparison with Motion Capture as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mocap_t, data_mocap_q, data_mocap_T, data_mocap_Markers_xyz = data_processing.import_mocap_data(mocap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mocap_t, data_mocap_q, data_mocap_T, data_mocap_Markers_xyz = data_processing.downsample(downscale, data_mocap_t, data_mocap_q, data_mocap_T, data_mocap_Markers_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_mocap_q, madgwick_IMU.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a098d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_data_zeroed = (t_base - t_base[0]) / 1000\n",
    "#t_data_all_sync, data_gyr_sync_mocap_my, data_acc_sync_mocap_my, data_magn_sync_mocap_my, data_quat_R_sync = madgwick_filter.sync_mocap_and_data(data_quat_t, data_quat_R, t_data_zeroed, data_gyr_my_sync, data_acc_my_sync, data_magn_my_sync)\n",
    "# no more need in sync, because it's done after TwistnSync launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_start = 0\n",
    "t_base, data_gyr, data_acc, data_magn, data_mocap_t, data_mocap_q = data_processing.arrays_from_i(i_start, t_base, data_gyr, data_acc, data_magn, data_mocap_t, data_mocap_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "madgwick_shifted_MARG = ahrs.filters.Madgwick(gyr=data_gyr,\n",
    "                                 acc=data_acc,\n",
    "                                 mag=data_magn,\n",
    "                                 frequency=freq_my)\n",
    "\n",
    "madgwick_shifted_IMU = ahrs.filters.Madgwick(gyr=data_gyr,\n",
    "                                 acc=data_acc,\n",
    "                                 frequency=freq_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(madgwick_shifted_MARG.Q)\n",
    "plot(madgwick_shifted_IMU.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_mocap_q, madgwick_shifted_MARG.Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3726f9",
   "metadata": {},
   "source": [
    "# Smartphone and Mocap data sync\n",
    "\n",
    "More information can be found in the [paper](https://www.mdpi.com/1424-8220/21/1/68).\n",
    "\n",
    "Here we find time offset and relative transformation between X3 Smartphone's sensors output and Motion Capture system data of tracking the smartphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8038c",
   "metadata": {},
   "source": [
    "## Filter without magnetometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sync_imu, qsa, qra = compare.compare_smartphone_to_mocap(t_base, madgwick_shifted_IMU.Q, data_gyr,\n",
    "                                                          data_mocap_t, data_mocap_q, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8dd7b",
   "metadata": {},
   "source": [
    "# Result depends on IMU smoothing window\n",
    "\n",
    "Walking dataset\n",
    "\n",
    "For exxample, starting with 5 error in the end is pretty low, but very big in middle. Then, for 10-20 error is quite big. For 40 it's 0.15 and 0.2.  For 70, final error is 0.134 - lowest, and in middle = 0.15. For 100 it's 0.3 and 0.1. For 200 every error grows.\n",
    "\n",
    "Result - need to find optimal smoothing window. Generally, increasing smoothing we lose final accuracy but increase intermediate accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b219ff9",
   "metadata": {},
   "source": [
    "## Sometimes filter with magnetometer shows better perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d86553",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.compare_smartphone_to_mocap(t_base, madgwick_shifted_MARG.Q, data_gyr,\n",
    "                                                          data_mocap_t, data_mocap_q, 100, gyro=False)      # need to set gyro=False, or the MARG data will not be even used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a6a92",
   "metadata": {},
   "source": [
    "# Madgwick filter and game rotation vector comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c915397",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sm, data_gyr, data_acc, data_magn = data_processing.import_combined_data(os.path.join(x3_path, \"combined_imu_data_7.csv\"))\n",
    "t_sm = t_sm / 1000                  # ms to s\n",
    "\n",
    "t_grv, gamerotvec = data_processing.import_gamerotvec_data(os.path.join(x3_path, \"game_rotation_vector_12.csv\"))\n",
    "t_grv = t_grv / 1000                  # ms to s\n",
    "\n",
    "compare.compare_smartphone_to_gamerotvec(t_sm, data_gyr, data_acc, data_magn, t_grv, gamerotvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407720f",
   "metadata": {},
   "source": [
    "# Madgwick filter and game rotation vector comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mocap_t, data_mocap_q, data_mocap_T, data_mocap_Markers_xyz = data_processing.import_mocap_data(mocap_path)\n",
    "\n",
    "compare.compare_gamerotvec_to_mocap(t_grv, gamerotvec, data_mocap_t, data_mocap_q, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
